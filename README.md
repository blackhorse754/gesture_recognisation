# gesture_recognisation
We have implemented hand gesture recognition using a Vision Transformer (ViT) model on Google's Soli dataset, replacing previous methods that relied on a fully trained end-to-end combination of deep convolutional and recurrent neural networks. The transition to ViT represents an innovative approach, showcasing adaptability in leveraging state-of-the-art architectures for improved accuracy in gesture recognition tasks. Results indicate the potential for ViT models to enhance performance in human-computer interaction applications. We achieved an impressive accuracy rate of 82-84% on the 11-class gesture recognition task using the deep-soli dataset and attained a low test loss of 0.113, demonstrating the model's efficiency and generalization on the specified datase
